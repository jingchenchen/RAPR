model:
  prompt_template: "a photo of x x"
  clip_model: "ViT-L/14"
  res_w: 0.8
  SA_K: 1
  LR_K: 12
  width_img: 1024
  width_txt: 768
  retrieval_weight: 0.5
  retrieval_temperature: 10.0
  retrieval_topk: 16
  att_obj_w: 0.2
  res_w_vis: 0.8
  res_w_vis_obj: 0.2 
  res_w_vis_att: 0.2   
  projection: mlp

train:
  dataset: cgqa
  dataset_path: "data/cgqa"
  lr: 0.0003
  attr_dropout: 0.3
  weight_decay: 0.00001
  context_length: 8
  train_batch_size: 16
  gradient_accumulation_steps: 1
  seed: 0
  epochs: 20
  epoch_start: 0
  best_model_metric: AUC     # best_unseen  best_seen AUC best_loss best_hm
  load_model: False     # False or model path
  save_path: saved_models/
  debias_loss_weight: 5.0
  retrieval_loss_topk: 32
  retrieval_loss_weight: 0.1

test:
  eval_batch_size: 128
  load_model:  saved_models/    # False or model path
  topk: 1
  threshold: 0.4
  threshold_trials: 50
  bias: 0.001